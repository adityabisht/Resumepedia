Biju Scaria Software Developer - IBM ISL- Email me on Indeed: indeed.com/r/Biju-Scaria/80f97dce80df91d7* Having around 10+ Years of experience in S/w Design, Development, Business Analysis, Testing, Implementation and Product Support* Hands on Experience in BigData, C, C++, Core Java, Struts and Springs framework, Oracle 11g and 12c RAC, Shell Scripting and well versed in most of the Unix and Linux flavors.* Hands on experience in installing, configuring and using Hadoop Ecosystem components like MapReduce, HDFS, HBase, ZooKeeper, Oozie, Hive, Sqoop, Pig, Flume.* Expertise in telecom mediation domain, prepaid as well as post paid. Good knowledge on diameter credit control applications.* Good knowledge of Design concepts, patterns and OOAD design skills.* Good Analytical and Programming skills.* Ability to lead and manage complete project life cycles, from initial planning/requirements gathering to final testing and deployment.* Good interpersonal and communication skills, commitment, result oriented, hardworking with a quest and zeal to learn new technologies and undertake challenging tasks1.Hadoop DeveloperEmployer IBM ISLClient Various clientsRole Technical LeadSoftware BigData Ecosystem, PowerLinux, AIX, Java, Shell scripting, AIX, REST APIs Team size 12Duration 29 August 2011 to till dateDescriptionProject aims at enabling different hadoop ecosystems on IBM PowerLinux platform and evangelizing IBM hadoop solution (Infoshpere BigInsights).Responsibilities and Tasks Performed• Enabling different ISV workloads and hadoop ecosystems to PowerLinux eco system.• Developed MapReduce programs in Java for data cleaning and preprocessing structured, semi- structured and unstructured raw data and store the refined data in partitioned tables in the Hive.• Used Flume to collect, aggregate, and store the log data from different sources like web servers, application servers and pushed to HDFS.• Designed an Enterprise Data Warehouse (EDW) using Hive & created partitioned tables.• Analyzed the web log data using the HiveQL to extract number of unique visitors per day, page• views, visit duration, most visited pages on website.• Created Hive queries that helped market analysts spot emerging trends by comparing fresh data with EDW reference tables and historical metrics.• Pig Latin scripts were used to analyze, clean and extract the results.• Exported the analyzed data to the relational databases using Sqoop for visualization and to generate reports by our BI team using Tableau.• Created HBase tables to load large sets of structured, semi-structured and unstructured data coming from a variety of sources.￼• Worked with systems engineering team to plan and deploy new Hadoop environments and expand existing Hadoop clusters.• Enabled speedy reviews and first mover advantages by using Oozie to automate data loading into the Hadoop Distributed File System and PIG to pre-process the data.• Installed and configured MapReduce, HIVE and the HDFS; implemented CDH4 Hadoop cluster on PowerLinux with performance tuning and monitoring.2.Mediation PracticeEmployer Convergys, HyderabadClient Various clients: CJ Australia, Tiscali ItalyRole Team LeadSoftware C++, Java, Digital Route mediation zone, Perl, Geneva RBMConfiguration Management Telelogic CM SynergyTeam size 6Duration 13 Sept 2010 to 26 Aug 2011.DescriptionMediation Practice is the team responsible for developing and implementing mediation requests from various clients of Convergys. Requests include development and customization of mediation systems, developing Proof of Concepts for new clients, providing custom solutions for Rating and Billing Manager of Convergys etc. Recently completed the migration of old mediation to new mediation for CJ. Worked as lead for the online charging implementation for Tiscali, Italy.Responsibilities and Tasks Performed• Worked as a team lead.• Requirement Analysis and HLD preparation.• Analysis, Design and Solution proposal• Technical decision making.• coding, Implementation and Unit testing• Mentoring and leading the mediation practice team.3.ScrubITEmployer Verizon Data Services, HyderabadClient Verizon BusinessRole Senior AnalystSoftware C++, Java, Struts, Oracle, Shell ScriptsConfiguration Management CvsTeam size 10Duration 1 April 2009 to 9 Sept 2010DescriptionScrubIT is the web based data masking solution of Verizon. ScrubIT aims at masking the sensitive information in production machines and makes the masked data available in dev and test environments. ScrubIT has the capability of masking files and databases. Recently a new product is launched by the team for online data masking by a proxy solution. File masking includes Ascii files, XML files, log files, Binary (Byte and Bit aligned). Files can be pulled to ScrubIT from any Unix/Windows or mainframe machine. Web interface of ScrubIT enables the users and admins to configure the file and database formats with ScrubIT and mask it on demand. Database masking including self update can be done online. ScrubIT offers wide variety of auditing and compare features of masking performed.Responsibilities and Tasks Performed• Worked as a senior analyst.• Requirement Analysis.• Analysis, Design and Solution proposal • Technical decision making.• coding, Implementation and Unit testing • Mentoring and leading a small group.4.Enhanced Traffic System (ETS)Employer Verizon Data Services, HyderabadClient Verizon BusinessRole Senior AnalystSoftware C++, Perl, Oracle, Shell ScriptsConfiguration Management PvcsTeam size 5Duration 17 September 2007 to 30 March 2009DescriptionEnhanced Traffic System (ETS) is a classic mediation system developed by Verizon for processing the switch record information. The call records created in various switched are mediated through ETS to the downstream systems such as billing, auditing etc. There are several modules in ETS which performs the business logic on these records such as classification, edits, translation, reference lookups etc. The main aim of this project is to replace the legacy call processing system with ETS.Responsibilities and Tasks Performed• Worked as a senior analyst.• Requirement capturing.• Analysis and Solution proposal.• Coding, Implementation and Unit testing.• Worked on two core modules, Enhance and pricing.• Grooming the new comers in the team.• Worked at Onsite (Colorado Springs, USA) for 2 months for business knowledge transfer.5.Air interface and Mobile Subscriber Simulator (AIMS).Employer Wipro Technologies, HyderabadClient EricssonRole Senior Project EngineerSoftware C, C++ Erlang, GSM AT commands, SIPConfiguration Management cvs, Rational clearcaseTeam size 14Duration October 2006 to 31 August 2007DescriptionAIMS is an end to end testing tool used for testing the GSM and UMTS networks by Ericsson. The project has an end to end delivery structure which includes hardware and software deliveries and support. AIMS is mainly used for system testing and regression testing of mobile networks across the globe by Ericsson verification team.Responsibilities and Tasks Performed• Worked as a senior project engineer.• Requirement capturing, Analysis, coding, Implementation, Unit testing. • Integration and system testing.• Rectification of Functionality Bugs, Rectification of coding bugs etc• Worked as AIMS First line support in EDD, Aachen, Germany for 6 months • Provided onsite support to the users of AIMS.• Installation and Upgrades of AIMS software and hardware at customer site • Trouble shooting and debugging• Hardware order handling.6.APS Tools maintenanceEmployer Wipro Technologies, Hyderabad.Client EricssonRole Project Engineer cum Sys AdminSoftware C, C++, Sybase, PowerBuilder, Perl, Shell Scripting, CitrixDuration May-2004 - May 2006DescriptionAPSTools is a sustenance project of supporting around 20 different tools used by Ericsson designers. The support and maintenance activities include providing solutions to the Questions, trouble reports, change requests raised by various user-groups, from Ericsson across the world.APSTools has two modules named Signal Handling Tools and PlexView ToolsResponsibilities and Tasks Performed• Worked as a Project Engineer with an additional responsibility of a sys admin.• Extensively involved in s/w development using Sybase SPs, C/C++, Java and Power Builder • Coding, Unit Testing, Implementation and User training• As part of the system studies visited the client location Aachen, Germany.• Installation, configuration and automation (if needed) of Ericsson proprietary tools• Resolving compilation issues in Sun Solaris and Linux platforms.• Administering, Supporting and Troubleshooting Sun SPARC servers and workstations• Solaris Installation, Configuration and System Administration• Resolving NIS, NFS issues of the team, load and process monitoring of Sun Servers.• Taking weekly and monthly backup ups of required file systems and clear case vobs.• Immediate support for Citrix and Rational clear case issues for the team.7.Vocal 14Employer Wipro Technologies, Hyderabad.Client Centre of Excellence, Wipro (Virtual team project)Role Module LeaderSoftware C++, Unix Shell scripts, SIP(Session Initiation Protocol), MySql, Fedora, Red Hat 9Duration Jan 2005 - Mar 2005DescriptionVOCAL 14 was a CoE (Centre of Excellence) initiative project of Wipro Technologies to set up the CoE lab in Hyderabad development centre. After the stable lab set up, Vocal servers which work on SIP protocol has to be installed and configured according to the requirements and various call features of Asterisk IP PBX should betested and verified. The project ended in setting up the complete predictive dialer, GNU Dialer in the simulated call centre scenario by using vocal servers and asterisk IP PBX.The project is basically aimed to build competency in upcoming technologies like SIP. VOCAL 14 was a project with 3 phases, each phase having duration of one month.Responsibilities and Tasks Performed• Worked as module leader• Guided the team effectively in entirely new technology areas • Delivered the product successfully meeting the deadlines.WORK EXPERIENCESoftware DeveloperIBM ISL - August 2011 to PresentAnalystConvergys - September 2010 to August 2011Senior AnalystVerizon Data Services - September 2007 to September 2010Senior Project EngineerWipro Technologies - April 2004 to August 2007Technical SkillsBigData Ecosystem Hadoop, MapReduce, HDFS, Hbase, ZooKeeper, Hive, Pig, Sqoop, Oozie and Flume Programming languages Java, C, C++, PowerBuilderDatabases Oracle RAC, Sybase, Sql Server, Redis (NoSql Database)Scripting Languages Shell Scripts (ksh and bash), Perl and RubyOperating System Sun Solaris, LoP, AIX, RHELSoftware Design & Architecture Design Patterns (GoF), OOAD design skillsWeb Application Frameworks & Technology JSP, Servlets, Struts MVC, AjaxBuild tools AntIDE Eclipse, NetbeansConfiguration Management Rational Clearcase, cvs, rcs, Telelogic CCMWeb Servers Apache Tomcat, JBoss, Resin, IISTools Rational Purify Plus, Valgrind, Citrix MetaFrame presentation serverEDUCATIONMaster of Computer ApplicationsMadurai Kamaraj University - Madurai, Tamil Nadu